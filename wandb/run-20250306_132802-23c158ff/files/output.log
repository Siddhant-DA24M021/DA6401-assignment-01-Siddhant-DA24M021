--------------------------------------------------------------------------------------------------
Epoch    1:      Training Loss -    2.33551   &   Training Accuracy -    0.09827
Epoch    2:      Training Loss -    2.30305   &   Training Accuracy -    0.09585
Epoch    3:      Training Loss -    2.30292   &   Training Accuracy -    0.09918
Epoch    4:      Training Loss -    2.30288   &   Training Accuracy -    0.09652
Epoch    5:      Training Loss -    2.30282   &   Training Accuracy -    0.09795
Epoch    6:      Training Loss -    2.30271   &   Training Accuracy -    0.09907
Epoch    7:      Training Loss -    2.30262   &   Training Accuracy -    0.09910
Epoch    8:      Training Loss -    2.30257   &   Training Accuracy -    0.09890
Epoch    9:      Training Loss -    2.30251   &   Training Accuracy -    0.10384
Traceback (most recent call last):
  File "C:\da24m021_da6401_assignment1\train.py", line 164, in <module>
    main()
  File "C:\da24m021_da6401_assignment1\train.py", line 118, in main
    model.backward()
  File "C:\da24m021_da6401_assignment1\neuralnetwork.py", line 17, in backward
    grad_output = layer.backward(grad_output) # This will populate the gradients of all the model parameters
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\da24m021_da6401_assignment1\activation.py", line 31, in backward
    dy_dh[j, k] = - self.output[i, j] * self.output[i, k]
    ~~~~~^^^^^^
KeyboardInterrupt
