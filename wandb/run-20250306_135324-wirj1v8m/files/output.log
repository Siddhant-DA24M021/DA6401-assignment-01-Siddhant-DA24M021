--------------------------------------------------------------------------------------------------
Epoch    1:      Training Loss -    1.17390   &   Training Accuracy -    0.63783
Epoch    2:      Training Loss -    1.08762   &   Training Accuracy -    0.62268
Epoch    3:      Training Loss -    1.08024   &   Training Accuracy -    0.62178
Epoch    4:      Training Loss -    1.08072   &   Training Accuracy -    0.62181
Epoch    5:      Training Loss -    1.07734   &   Training Accuracy -    0.62671
Epoch    6:      Training Loss -    1.08036   &   Training Accuracy -    0.62148
Epoch    7:      Training Loss -    1.08066   &   Training Accuracy -    0.62243
Traceback (most recent call last):
  File "C:\da24m021_da6401_assignment1\train.py", line 164, in <module>
    main()
  File "C:\da24m021_da6401_assignment1\train.py", line 118, in main
    model.backward()
  File "C:\da24m021_da6401_assignment1\neuralnetwork.py", line 17, in backward
    grad_output = layer.backward(grad_output) # This will populate the gradients of all the model parameters
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\da24m021_da6401_assignment1\linearlayer.py", line 24, in backward
    self.dbias = np.sum(grad_output, axis = 0 , keepdims=True)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Siddhant\AppData\Local\Programs\Python\Python312\Lib\site-packages\numpy\_core\fromnumeric.py", line 2466, in sum
    return _wrapreduction(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Siddhant\AppData\Local\Programs\Python\Python312\Lib\site-packages\numpy\_core\fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
