# Activation functions

def relu():
    pass

def sigmoid():
    pass

def tanh():
    pass

def softmax():
    pass